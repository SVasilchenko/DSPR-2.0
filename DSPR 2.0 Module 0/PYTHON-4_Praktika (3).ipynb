{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liFg08vGk-Ou"
   },
   "source": [
    "# <center> Практическое задание по теме \"Циклы\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZQ8hwHMphX3"
   },
   "source": [
    "<img src=https://1gai.ru/uploads/posts/2020-12/1608804716_54441.png width=300 align=\"right\">\n",
    "\n",
    "→ Поздравляем с освоением важных для анализа данных конструкций Python (переменные, структуры данных, условные операторы и циклы)!\n",
    "\n",
    "Настало время промежуточной практики, чтобы закрепить все полученные в предыдущих модулях навыки! Мы будем применять их на реальном проекте. Сегодня мы обратимся к классике: займемся анализом текстов на примере «Войны и мира» Льва Николаевича Толстого!\n",
    "\n",
    "В рамках практического кейса мы сначала вместе познакомимся с исходными данными и произведем некоторые манипуляции над ними. После чего вам предстоит самостоятельно выполнить несколько заданий на тему поиска наиболее значимых слов в тексте с помощью методов статистического анализа текста. \n",
    "\n",
    "> Итак, приступим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgQNPhZ4k68p"
   },
   "source": [
    "## <center> Знакомимся с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn4Fncpvk6Va"
   },
   "source": [
    "Текст произведения мы взяли в библиотеке [lib.ru](http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0073.shtml) и провели первоначальную обработку. Поскольку наша цель — обработка слов из этого произведения, мы разбили текст на слова и вывели каждое слово в отдельной строке. Кроме того, в местах, где начинаются главы, мы вывели строку `\"[new chapter]\"`.\n",
    "\n",
    "> Исходный текстовый файл хранится в общем доступе и находится [здесь](https://raw.githubusercontent.com/SkillfactoryDS/Datasets/master/war_peace_processed.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGItOdWbx4KT"
   },
   "source": [
    "Для начала скачаем текст книги по ссылке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1676119623058,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "h8cSMJp2anzX",
    "outputId": "84e5f85c-8b7c-4634-a729-b9c195bb7def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'в', 'два', 'раза', 'короче', 'и', 'в', 'пять', 'раз', 'интереснее', '2', 'почти', 'нет', 'философических', 'отступлений', '3', 'в', 'сто', 'раз', 'легче', 'читать', 'весь', 'французский', 'текст', 'заменен', 'русским', 'в', 'переводе', 'самого', 'толстого', '4', 'гораздо', 'больше', 'мира', 'и', 'меньше', 'войны', '5', 'хеппи-энд', 'эти', 'слова', 'я', 'поместил', 'семь', 'лет', 'назад', 'на', 'обложку', 'предыдущего', 'издания', 'указав', 'в', 'аннотации', 'первая', 'полная', 'редакция', 'великого', 'романа', 'созданная', 'к', 'концу', '1866', 'года', 'до', 'того', 'как', 'толстой', 'переделал', 'его', 'в', '1867--1869', 'годах', '--', 'и', 'что', 'я', 'использовал', 'такие-то', 'публикации', 'думая', 'что', 'все', 'всё', 'знают', 'я', 'не', 'объяснил', 'откуда', 'взялась', 'эта', 'первая', 'редакция', 'я', 'оказался', 'неправ', 'и', 'в', 'результате', 'оголтелые', 'и']\n"
     ]
    }
   ],
   "source": [
    "# Импортируем библиотеку для выполнения HTTP-запросов в интернет\n",
    "import requests \n",
    "\n",
    "# Читаем текстовый файл по url-ссылке\n",
    "data = requests.get(\"https://raw.githubusercontent.com/SkillfactoryDS/Datasets/master/war_peace_processed.txt\").text\n",
    "\n",
    "# Предобрабатываем текстовый файл\n",
    "data = data.split('\\n')\n",
    "data.remove('')\n",
    "data = data + ['[new chapter]']\n",
    "\n",
    "# Выводим первые 100 слов из книги\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeTg-aKgCwye"
   },
   "source": [
    "## <center> Работаем с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpn_8XFRCo7o"
   },
   "source": [
    "Для начала найдем общее количество слов и количество уникальных слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1676119232106,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "dPNZVk27wkpM",
    "outputId": "4852e43f-b382-4872-d611-e5e2f27d30f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество слов: 300080\n",
      "Общее количество уникальных слов: 38210\n"
     ]
    }
   ],
   "source": [
    "# Превращаем список в множество, удаляя дублирующиеся слова\n",
    "word_set = set(data)\n",
    "# Удаляем из множества слово, символизирующее раздел между главами\n",
    "word_set.discard('[new chapter]')\n",
    "# Выводим результаты\n",
    "print('Общее количество слов: {}'.format(len(data)))\n",
    "print('Общее количество уникальных слов: {}'.format(len(word_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShCV0QIAqCsG"
   },
   "source": [
    "Давайте напишем программу, которая посчитает частоту каждого слова. Для этого создадим словарь, ключами которого будут являться слова, а значения - количество вхождений этого слова в текст произведения. Заодно подсчитаем количество глав"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1676028840628,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "Hzd2YuYZeCf5",
    "outputId": "e0d1e049-a517-4b32-9831-991754b015d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество глав: 171\n",
      "1 10\n",
      "в 6997\n",
      "два 215\n",
      "раза 35\n",
      "короче 3\n",
      "и 14592\n",
      "пять 61\n",
      "раз 296\n",
      "интереснее 4\n",
      "2 12\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем пустой словарь\n",
    "word_counts = {}\n",
    "# Инициализируем количество глав\n",
    "count_chapter = 0\n",
    "# Создаем цикл по всем словам из списка слов\n",
    "for word in data:\n",
    "    # Проверяем, что текущее слово - обозначение новой главы\n",
    "    if word == '[new chapter]':\n",
    "        # Если условие выполняется, то увеличиваем количество глав на 1\n",
    "        count_chapter += 1\n",
    "        # Переходим на новую итерацию цикла\n",
    "        continue\n",
    "    # Проверяем, что текущего слова еще нет в словаре слов\n",
    "    if word not in word_counts:\n",
    "        # Если условие выполняется, инициализируем новый ключ 1\n",
    "        word_counts[word] = 1\n",
    "    else:\n",
    "        # В противном случае, увеличиваем количество слов на 1\n",
    "        word_counts[word] += 1\n",
    "\n",
    "# Выводим количество глав\n",
    "print('Количество глав: {}'.format(count_chapter))\n",
    "\n",
    "# Создаем цикл по ключам и их порядковым номерам полученного словаря\n",
    "for i, key in enumerate(word_counts):\n",
    "    # Выводим только первые 10 слов\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(key, word_counts[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRo9-Xr-rFwP"
   },
   "source": [
    "Разделим все слова на главы. Для этого создадим список, в котором будем хранить списки - слова из определенной главы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1676120047563,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "WsdGmz-frFf0",
    "outputId": "60416c2b-9074-4eb6-aa0f-a5b6682ab364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вложенный список содержит 171 внутренних списка\n",
      "['1', 'в', 'два', 'раза', 'короче', 'и', 'в', 'пять', 'раз', 'интереснее', '2', 'почти', 'нет', 'философических', 'отступлений', '3', 'в', 'сто', 'раз', 'легче', 'читать', 'весь', 'французский', 'текст', 'заменен', 'русским', 'в', 'переводе', 'самого', 'толстого', '4', 'гораздо', 'больше', 'мира', 'и', 'меньше', 'войны', '5', 'хеппи-энд', 'эти', 'слова', 'я', 'поместил', 'семь', 'лет', 'назад', 'на', 'обложку', 'предыдущего', 'издания', 'указав', 'в', 'аннотации', 'первая', 'полная', 'редакция', 'великого', 'романа', 'созданная', 'к', 'концу', '1866', 'года', 'до', 'того', 'как', 'толстой', 'переделал', 'его', 'в', '1867--1869', 'годах', '--', 'и', 'что', 'я', 'использовал', 'такие-то', 'публикации', 'думая', 'что', 'все', 'всё', 'знают', 'я', 'не', 'объяснил', 'откуда', 'взялась', 'эта', 'первая', 'редакция', 'я', 'оказался', 'неправ', 'и', 'в', 'результате', 'оголтелые', 'и']\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем общий список, в котором будем хранить списки слов в каждой главе\n",
    "chapter_data = []\n",
    "# Инициализируем список слов, в котором будет хранить слова одной главы\n",
    "chapter_words = []\n",
    "\n",
    "# Создаем цикл по всем словам из списка\n",
    "for word in data:\n",
    "    # Проверяем, что текущее слово - обозначение новой главы\n",
    "    if word == '[new chapter]':\n",
    "        # Если условие выполняется, добавляем список со словами из главы в общий список\n",
    "        chapter_data.append(chapter_words)\n",
    "        # Обновляем (перезаписываем) список со словами из текущей главы\n",
    "        chapter_words = []\n",
    "    else:\n",
    "        # В противном случае, добавляем текущее слово в список со словами из главы\n",
    "        chapter_words.append(word)\n",
    "\n",
    "# Проверяем, что у нас получилось столько же списков, сколько глав в произведении\n",
    "print('Вложенный список содержит {} внутренних списка'.format(len(chapter_data)))\n",
    "# Выведем первые 100 слов 0-ой главы\n",
    "print(chapter_data[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1676120111205,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "TM0OaA3pinfQ",
    "outputId": "00ffd7f0-5970-4d86-eb39-a968448cfc10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_data[15][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saO-dds9h-Mo"
   },
   "source": [
    "Подсчитаем, сколько раз каждое слово встречается в каждой из глав"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3312,
     "status": "ok",
     "timestamp": 1676120228035,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "6oGOvOHxGt3M",
    "outputId": "0bc775a7-1a5f-4912-8e59-7242478fa8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 1, 'в': 37, 'два': 3, 'раза': 1, 'короче': 1, 'и': 34, 'пять': 1, 'раз': 2, 'интереснее': 1, '2': 1, 'почти': 1, 'нет': 1, 'философических': 1, 'отступлений': 1, '3': 1, 'сто': 1, 'легче': 1, 'читать': 1, 'весь': 2, 'французский': 2, 'текст': 3, 'заменен': 1, 'русским': 1, 'переводе': 1, 'самого': 2, 'толстого': 5, '4': 1, 'гораздо': 1, 'больше': 1, 'мира': 3, 'меньше': 1, 'войны': 3, '5': 1, 'хеппи-энд': 1, 'эти': 2, 'слова': 2, 'я': 8, 'поместил': 1, 'семь': 1, 'лет': 2, 'назад': 1, 'на': 7, 'обложку': 1, 'предыдущего': 1, 'издания': 3, 'указав': 1, 'аннотации': 1, 'первая': 2, 'полная': 1, 'редакция': 2, 'великого': 1, 'романа': 5, 'созданная': 1, 'к': 4, 'концу': 2, '1866': 3, 'года': 5, 'до': 1, 'того': 1, 'как': 2, 'толстой': 6, 'переделал': 1, 'его': 5, '1867--1869': 1, 'годах': 2, '--': 10, 'что': 9, 'использовал': 2, 'такие-то': 1, 'публикации': 1, 'думая': 1, 'все': 2, 'всё': 7, 'знают': 1, 'не': 11, 'объяснил': 1, 'откуда': 1, 'взялась': 1, 'эта': 1, 'оказался': 1, 'неправ': 1, 'результате': 2, 'оголтелые': 1, 'невежественные': 1, 'критики': 1, 'выдающие': 1, 'себя': 1, 'за': 2, 'знатоков': 1, 'русской': 1, 'литературы': 1, 'публично': 1, 'стали': 1, 'обвинять': 1, 'меня': 2, 'фальсификации': 1, 'это': 3, 'захаров': 2, 'сам': 2, 'сляпал': 1, 'надругательстве': 1, 'над': 2, 'толстым': 1, 'ведь': 1, 'вот': 2, 'же': 2, 'лев': 1, 'николаевич': 1, 'напечатал': 1, 'этот': 3, 'первый': 2, 'вариант': 2, 'а': 5, 'вы': 1, 'по-прежнему': 1, 'считаю': 1, 'необходимым': 1, 'подробно': 1, 'излагать': 1, 'предисловиях': 1, 'то': 3, 'можно': 2, 'найти': 1, 'специальной': 1, 'литературе': 1, 'но': 2, 'нескольких': 1, 'строках': 1, 'объясню': 1, 'итак': 1, 'лнтолстой': 1, 'писал': 2, 'роман': 2, 'с': 9, '1863': 1, 'поставив': 1, '726-й': 1, 'странице': 1, 'слово': 1, 'конец': 1, 'повез': 1, 'москву': 1, 'печатать': 3, 'этому': 1, 'времени': 1, 'он': 4, 'уже': 1, 'опубликовал': 1, 'две': 1, 'первые': 1, 'части': 1, '1805': 1, 'война': 2, 'журнале': 1, 'русский': 2, 'вестник': 1, 'отдельной': 1, 'книгой': 1, 'заказал': 1, 'художнику': 1, 'мсбашилову': 1, 'иллюстрации': 1, 'для': 6, 'полного': 2, 'книжного': 1, 'издать': 1, 'книгу': 1, 'смог': 1, 'катков': 1, 'уговаривал': 1, 'продолжать': 1, 'кусками': 1, 'своем': 1, 'русском': 1, 'вестнике': 1, 'другие': 1, 'издатели': 1, 'смущаясь': 1, 'объемом': 1, 'неактуальностью': 1, 'произведения': 1, 'лучшем': 1, 'случае': 1, 'предлагали': 1, 'автору': 1, 'свой': 1, 'счет': 1, 'художник': 1, 'башилов': 1, 'работал': 3, 'очень': 1, 'неспешно': 1, 'переделывал': 1, 'соответствии': 2, 'письменными': 1, 'указаниями': 1, 'еще': 2, 'медленнее': 1, 'оставшаяся': 1, 'ясной': 1, 'поляне': 1, 'жена': 1, 'софья': 1, 'андреевна': 1, 'настоятельно': 1, 'требовала': 1, 'чтобы': 1, 'муж': 1, 'скорее': 1, 'возвращался': 1, 'дети': 1, 'плачут': 1, 'зима': 1, 'носу': 1, 'делами': 1, 'по': 1, 'хозяйству': 1, 'ей': 1, 'одной': 1, 'трудно': 1, 'справиться': 1, 'ну': 1, 'наконец': 1, 'только': 3, 'открывшейся': 1, 'тогда': 1, 'публичного': 1, 'пользования': 1, 'чертковской': 1, 'библиотеке': 1, 'бартенев': 1, 'будущий': 1, 'редактор': 1, 'показал': 1, 'толстому': 1, 'много': 1, 'материалов': 1, 'которые': 1, 'писатель': 1, 'захотел': 1, 'использовать': 1, 'своей': 1, 'книге': 2, 'заявив': 1, 'лучшему': 1, 'обыграл': 1, 'первоначальное': 1, 'название': 1, 'своего': 1, 'хорошо': 2, 'кончается': 1, 'уехал': 1, 'рукописью': 3, 'домой': 1, 'ясную': 2, 'поляну': 2, 'текстом': 1, 'мир': 1, 'была': 1, 'впервые': 1, 'издана': 1, 'целиком': 1, 'шести': 1, 'томах': 1, '1868--1869': 1, 'причём': 1, 'без': 1, 'иллюстраций': 1, 'башилова': 1, 'который': 1, 'так': 2, 'завершил': 1, 'свою': 2, 'работу': 1, 'неизлечимо': 1, 'заболел': 1, 'умер': 1, '1870': 1, 'году': 2, 'тироле': 1, 'собственно': 1, 'вся': 1, 'история': 1, 'теперь': 1, 'о': 1, 'происхождении': 1, 'текста': 1, 'вернувшись': 1, 'конце': 2, 'естественно': 1, 'убирал': 1, 'полку': 1, '726-страничную': 1, 'рукопись': 2, 'чтоб': 1, 'начать': 1, 'начала': 2, 'первой': 1, 'страницы': 2, 'той': 1, 'дописывал': 1, 'вычёркивал': 1, 'переставлял': 1, 'обороте': 1, 'добавлял': 1, 'новые': 1, 'листы': 1, 'спустя': 1, 'пятьдесят': 1, 'музее': 1, 'остоженке': 1, 'москве': 1, 'где': 1, 'хранились': 1, 'рукописи': 2, 'писателя': 1, 'работать': 1, 'проработала': 1, 'там': 1, 'несколько': 1, 'десятилетий': 1, 'эвелина': 1, 'ефимовна': 1, 'зайденшнур': 1, 'она': 2, 'расшифровывала': 1, 'распечатывала': 1, 'собрания': 1, 'сочинений': 1, 'ей-то': 1, 'мы': 1, 'обязаны': 1, 'возможностью': 1, 'прочитать': 1, 'реконструировала': 1, 'первоначальную': 1, 'сличая': 1, 'почерк': 1, 'цвет': 1, 'чернил': 1, 'бумагу': 1, 'тд': 1, '1983': 1, 'был': 1, 'опубликован': 2, '94-м': 1, 'томе': 1, 'литературного': 1, 'наследства': 1, 'издательства': 1, 'наука': 1, 'ан': 1, 'ссср': 1, 'специалистов': 1, 'точном': 1, 'которая': 1, 'оставалась': 1, 'неотредактированной': 1, 'мне': 1, 'дипломированному': 1, 'филологу': 1, 'редактору': 1, '30-летним': 1, 'стажем': 1, 'досталась': 1, 'самая': 1, 'лёгкая': 1, 'приятная': 1, 'работа': 1, 'причесать': 1, 'есть': 1, 'сделать': 1, 'приемлемым': 1, 'широкого': 1, 'читателя': 1, 'вычитать': 1, 'исправить': 1, 'грамматические': 1, 'ошибки': 1, 'уточнить': 1, 'нумерацию': 1, 'глав': 1, 'тп': 1, 'при': 1, 'этом': 1, 'правил': 2, 'нельзя': 1, 'было': 2, 'править': 2, 'например': 1, 'пьер': 1, 'у': 1, 'пьёт': 1, 'клубе': 1, 'шато': 1, 'марго': 2, 'алито': 1, 'лит': 1, 'наследстве': 1, 'концов': 1, 'самое': 1, 'последнее': 1, 'второго': 1, '1873': 1, 'год': 1, 'перевёл': 1, 'этой': 1}\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем список, в котором будем хранить словари\n",
    "chapter_words_count = []\n",
    "\n",
    "# Создаем цикл по элементам внешнего списка со словами\n",
    "for chapter_words in chapter_data:\n",
    "    # Инициализируем пустой словарь, куда будем добавлять результаты\n",
    "    temp = {}\n",
    "    # Создаем цикл по элементам внутреннего списка\n",
    "    for word in chapter_words:\n",
    "        # Проверяем, что текущего слова еще нет в словаре\n",
    "        if word not in temp:\n",
    "            # Если условие выполняется, добавляем ключ в словарь\n",
    "            temp[word] = 1\n",
    "        else:\n",
    "            # В противном случае, увеличиваем количество влождений слова в главу\n",
    "            temp[word] += 1\n",
    "    # Добавляем получившийся словарь в список\n",
    "    chapter_words_count.append(temp)\n",
    "\n",
    "# Выводим результат\n",
    "print(chapter_words_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1676120267681,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "ytU4Um8vjUqi",
    "outputId": "dc415190-cf84-406f-b252-e26413510413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_words_count[15]['князю']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1676029766211,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "iBIS01d0tYNi",
    "outputId": "c239da04-d68d-4eda-be83-69aa804b89c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Chapter: 0\n",
      "----------------------------------------\n",
      "1 1\n",
      "в 37\n",
      "два 3\n",
      "раза 1\n",
      "короче 1\n",
      "и 34\n",
      "пять 1\n",
      "раз 2\n",
      "интереснее 1\n",
      "2 1\n",
      "----------------------------------------\n",
      "Chapter: 1\n",
      "----------------------------------------\n",
      "автора 1\n",
      "я 20\n",
      "пишу 2\n",
      "до 1\n",
      "сих 1\n",
      "пор 1\n",
      "только 5\n",
      "о 2\n",
      "князьях 1\n",
      "графах 1\n",
      "----------------------------------------\n",
      "Chapter: 2\n",
      "----------------------------------------\n",
      "первая 1\n",
      "----------------------------------------\n",
      "Chapter: 3\n",
      "----------------------------------------\n",
      "-- 81\n",
      "ну 5\n",
      "что 44\n",
      "князь 21\n",
      "генуя 1\n",
      "и 94\n",
      "лукка 1\n",
      "стали 1\n",
      "не 57\n",
      "больше 2\n",
      "----------------------------------------\n",
      "Chapter: 4\n",
      "----------------------------------------\n",
      "гостиная 1\n",
      "анны 2\n",
      "павловны 2\n",
      "начала 1\n",
      "понемногу 1\n",
      "наполняться 1\n",
      "приехала 3\n",
      "высшая 1\n",
      "знать 1\n",
      "петербурга 2\n"
     ]
    }
   ],
   "source": [
    "# Создаем цикл по ключам словаря - спискам слов и их порядковым номерам\n",
    "for chapter_number, chapter_dict in enumerate(chapter_words_count):\n",
    "    # Выводим только первые 5 глав\n",
    "    if chapter_number == 5:\n",
    "        break\n",
    "    # Выводим номер главы\n",
    "    print('-' * 40)\n",
    "    print('Chapter: {}'.format(chapter_number))\n",
    "    print('-' * 40)\n",
    "    # Создаем цикл по ключам - словам и их порядковым номерам\n",
    "    for j, word in enumerate(chapter_dict):\n",
    "        # Выводим первые 10 слов из главы\n",
    "        if j == 10:\n",
    "            break\n",
    "        print(word, chapter_dict[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVkFtTfgiMAM"
   },
   "source": [
    "Давайте резюмировать, что мы с вами уже получили:\n",
    "\n",
    "* `word_set` - множество из всех слов, которые есть в книге\n",
    "\n",
    "* `count_chapter` - количество глав в книге (171)\n",
    "\n",
    "* `word_counts` - словарь, ключами которого являются слова, а значениями - количество вхождений этих слов в книгу\n",
    "\n",
    "* `chapter_data` - список из 171 списка, где элементы вложенных списков - все слова из главы. Каждый список соответствует своей главе\n",
    "\n",
    "* `chapter_words_count` - список из 171 словаря, где ключи - слова, а значения - количество слов в главе. Каждый словарь соответствует своей главе\n",
    "\n",
    "Учтите, что эти данные могут пригодиться вам при выполнении дальнейших заданий.\n",
    "\n",
    "> А теперь к заданиями!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4Gq7Waelsji"
   },
   "source": [
    "## <center> Задания для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6gX5LrcKrJw"
   },
   "source": [
    "### Задание 1.\n",
    "\n",
    "Давайте введем понятие частоты употребления отдельного слова в документе (`term frequency`, или `tf`). В нашем случае речь идёт не о документах, а о главах книги (выше мы писали, что в текстовом документе главы разделяются строкой '[new chapter]').\n",
    "\n",
    "Формула для вычисления `term frequency` для слова `word`:\n",
    "$$ tf_{word, chapter} = \\frac {n_{word, chapter}} {n_{chapter}}$$\n",
    "\n",
    "где \n",
    "* ${n_{word, chapter}}$ - сколько раз слово `word` встрачается в главе `chapter`, \n",
    "* $n_{chapter}$ - количество слов в главе `chapter`.\n",
    "\n",
    "\n",
    "Например, слово `\"гостья\"` употребляется в 15-ой главе 10 раз (${n_{word, chapter}}$).(кстати, главы у нас нумеруются с 0). Общее количество слов в тексте 15-ой главы - 1359 ($n_{chapter}$). Тогда:\n",
    "\n",
    "$$ tf_{гостья, 15} = \\frac{10}{1359} \\approx 0.007358$$\n",
    "\n",
    "**Задание:** \n",
    "\n",
    "Напишите программу, которая позволит получать частоту употребления любого заданного слова `target_word` в заданной главе `target_chapter`. \n",
    "\n",
    "**Дополнительное требование:**\n",
    "\n",
    "*Пострайтесь сделать программу максимально обобщенной. То есть желательно рассчитать характеристику `tf` для всех слов из каждой главы, чтобы впоследствии не было необходимости производить вычисления снова.*\n",
    "\n",
    "**Подсказка:**\n",
    "\n",
    "*Для этого вы можете для каждой главы создать словарь, ключами которого являются слова, а значения - частота употребления этого слова в этой главе*\n",
    "\n",
    "**Протестируйте работу программы на нескольких словах и главах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xCs_lzDEPpJZ"
   },
   "outputs": [],
   "source": [
    "# Имеем переменную chapter_words_count. Нам нужно каждое значение каждого словаря внутри этого списка разделить на количество слов в соответствующей главе.\n",
    "tf_count = []                                               # Cписок словарей со значениями tf\n",
    "\n",
    "for ch_num, word_dict in enumerate(chapter_words_count):\n",
    "    tf_chapter = {}                                         # Словарь значений tf для данной главы. Наполняется во вложенном цикле.\n",
    "    len_chapter = len(chapter_data[ch_num])                 # Посчитаем количество слов в главе ch_num\n",
    "    \n",
    "    for word, value in word_dict.items():                   # Итерируем словарь word_dict главы ch_num, добавляя в словарь tf_chapter ключи-слова и значения tf\n",
    "        tf_chapter.setdefault(word, value/len_chapter)\n",
    "    \n",
    "    tf_count.append(tf_chapter)                             # Добавляем полученный словарь в список словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012048192771084338\n"
     ]
    }
   ],
   "source": [
    "target_word = 'князь'\n",
    "target_chapter = 12\n",
    "try:\n",
    "    print(tf_count[target_chapter][target_word])\n",
    "except KeyError:\n",
    "    print(f'Слова \"{target_word}\" нет в главе {target_chapter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyZ5EhoLRbnG"
   },
   "source": [
    "### Задание 2.\n",
    "\n",
    "Пришло время познакомиться с понятием `document frequency`.\n",
    "\n",
    "`Document frequency` (для удобства сократим до `df`) — это доля документов, в которых встречается искомое слово. \n",
    "\n",
    "Вычисляется по формуле:\n",
    "\n",
    "$$ df_{word} = \\frac{N_{word}}{N} $$, \n",
    "\n",
    "где \n",
    "* $N_{word}$ - число документов (глав) содержащих слово `word`, \n",
    "* $N$ - общее число документов (глав).\n",
    "\n",
    "Объясним на примере: наш текст состоит из 171 главы ($N$), а слово `\"человек\"` встречается в 115 главах. Тогда:\n",
    "\n",
    "$$ df_{человек} = \\frac{115}{171} \\approx 0.6725$$\n",
    "\n",
    "**Задание:** \n",
    "\n",
    "Напишите программу, которая позволит вычислять document frequency для заданного слова `target_word` и выведить результат на экран.\n",
    "\n",
    "**Дополнительное требование:**\n",
    "\n",
    "*Пострайтесь сделать программу максимально обобщенной. То есть желательно рассчитать характеристику `df` для всех уникальных слов из книги, чтобы впоследствии не было необходимости производить вычисления снова.*\n",
    "\n",
    "**Подсказка:**\n",
    "*Для этого вы можете создать словарь, ключами которого являются слова из книги, а значения - доля документов, содержащих эти слова*\n",
    "\n",
    "**Протестируйте работу программы на нескольких словах** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e8EN3GZ1YCqB"
   },
   "outputs": [],
   "source": [
    "# Можно было перевести списки во множества, чтобы не таскаться со значениями, которые нам все равно не нужны.\n",
    "# Но т.к. большого выигрыша от этого я не увидел, то работаю со словарями\n",
    "\n",
    "df_count = {}                                         # Словарь значений df, будем наполнять\n",
    "\n",
    "for word in word_counts.keys():                       # итерируем уникалльные слова в тексте\n",
    "    df_count.update({word: 0})                        # добавляем ключ-слово присваиваем значение 0\n",
    "    for chapter_words in chapter_words_count:         # итеррируем словари по главам\n",
    "        if chapter_words.get(word) is not None:       # Проверяем есть ли ключ (слово) в данной главе\n",
    "            df_count[word] += 1                       # если есть увеличиваем занчение на 1\n",
    "    df_count[word] = df_count[word]/count_chapter     # Пересчитываем результат в df, записываем в то же место."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672514619883041\n"
     ]
    }
   ],
   "source": [
    "target_word = 'человек'\n",
    "\n",
    "try:\n",
    "    print(df_count[target_word])\n",
    "except KeyError:\n",
    "    print(f'Слова \"{target_word}\" нет в тексте')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS78rqWDYZMo"
   },
   "source": [
    "### Задание 3\n",
    "\n",
    "Пришло время дать разъяснения: для чего мы делали вычисления выше и что нас ждет впереди?\n",
    "\n",
    "> Если какое-то слово часто употребляется в документе, то, вероятно, этот документ что-то рассказывает о предмете/действии, описываемом этим словом. Скажем, если вы читаете книгу, в которой много раз употребляется слово `\"заяц\"`, то, вероятно, эта книга про зайцев.\n",
    "\n",
    "> Однако, если вы возьмёте слово `\"и\"`, то оно будет встречаться почти в каждой книге много раз. \n",
    "\n",
    "Таким образом, если мы хотим найти наиболее значимые слова в книге, мы, с одной стороны, хотим найти наиболее частые слова, а с другой — убрать те, которые не несут важной информации, так как встречаются везде.\n",
    "\n",
    "Такая задача хорошо решается с помощью `tf-idf` — статистической метрики для оценки важности слова в тексте. Другими словами, `tf-idf` — это «контрастность» слова в документе (насколько оно выделяется среди других слов). \n",
    "\n",
    "Формула для вычисления следующая:\n",
    "\n",
    "`tf-idf = term frequency * inverse document frequency`\n",
    "\n",
    "* `tf` — это частотность термина, которая измеряет, насколько часто термин встречается в документе.\n",
    "\n",
    "* `idf` — это обратная документная частотность термина. Она измеряет непосредственно важность термина во всём множестве документов.\n",
    "\n",
    "Чтобы получить `idf`, необходимо поделить 1 на полученную в Задании 2 документную частоту (`df`):\n",
    "\n",
    "$$idf = \\frac{1}{df}$$\n",
    "\n",
    "Мы будем использовать не сырые значения `idf`, а их логарифмы, то есть $tf * log(idf)$. Сейчас мы не будем заострять внимания на том, почему следует использовать именно логарифм — это долгий разговор. Вернемся к нему, когда будем изучать методы машинного обучения для обработки текстов. Подробнее о `tf-idf` вы можете почитать [здесь](https://translated.turbopages.org/proxy_u/en-ru.ru.15518a02-63e76541-6895b80b-74722d776562/https/www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/).\n",
    "\n",
    "В качестве примера измерим `tf-idf` слова `\"анна\"` в главе 4. Слово `\"анна\"` встречается в указанной главе 7 раз, при этом в 4 главе 1060 слов, всего же слово `\"анна\"` упоминается в 32 главах из 171.\n",
    "\n",
    "Таким образом, `tf-idf` данного слова в данной главе будет равно:\n",
    "\n",
    "$$tf\\_idf_{анна, 4} = tf * log(\\frac{1}{df}) = \\frac{7}{1060} * log(\\frac {171}{32}) \\approx 0.011067$$\n",
    "\n",
    "**Примечание:** здесь используется натуральный логарифм по основанию $e$, однако в общем случае основание логарифма не имеет значения, так как характеристика `tf-idf` используется для сравнения контрастности слов между собой\n",
    "\n",
    "**Задание**:\n",
    "\n",
    "Напишите программу, которая позволяет вычислять значение `tf-idf` для заданного слова `target_word` в заданной главе `target_chapter`.\n",
    "\n",
    "**Дополнительное требование:**\n",
    "\n",
    "*Пострайтесь сделать программу максимально оптимальной. То есть желательно рассчитать характеристику `tf-idf` для всех слов из каждой главы книги, чтобы впоследствии не было необходимости производить вычисления снова.*\n",
    "\n",
    "**Протестируйте работу программы на нескольких словах и главах.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvdwTW_459uh"
   },
   "source": [
    "**Примечание:**\n",
    "\n",
    "Натуральный логарифм можно вычислить с помощью функции [log](https://pythonim.ru/chisla/funktsiya-log-v-python) из встроенного в Python модуля math:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676109649569,
     "user": {
      "displayName": "Андрей Достоевский",
      "userId": "09718989537568551698"
     },
     "user_tz": -180
    },
    "id": "hX5UCiwj63FD",
    "outputId": "3f33848f-09e1-4fc0-854b-c590f84150e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8903717578961645\n"
     ]
    }
   ],
   "source": [
    "# Импортируем функцию log из модуля math:\n",
    "from math import log\n",
    "print(log(18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk_gYbsJ7ayr"
   },
   "source": [
    "**Примечание.** \n",
    "\n",
    "**Модуль (библиотека) в Python** — это любой программный файл, который содержит в себе код, включая функции. В нашем случае math — это встроенный модуль, содержащий функционал для математических вычислений. Подробнее о math вы можете почитать [здесь](https://pythonworld.ru/moduli/modul-math.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pDB99Uu_2QG-"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "tf_idf_count = []                              # Создаем пустой список\n",
    "for word_dict in tf_count:                     # Итерируем список по словарям\n",
    "    tf_idf_dict = {}                           # Создаем пустой словарь, который будем заполнять значениями tf-idf\n",
    "    for word, tf in word_dict.items():         # Словарь word_dict итерируем по элементам (слово, значение tf) \n",
    "        tf_idf = tf * log(1/df_count[word])    # Для каждого слова считаем tf_idf \n",
    "        tf_idf_dict.update({word: tf_idf})     # добавляем результат в словарь\n",
    "    tf_idf_count.append(tf_idf_dict)           # добавляем получившийся словарь в список"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009813990764927087\n"
     ]
    }
   ],
   "source": [
    "target_word = 'анна'\n",
    "target_chapter = 3\n",
    "try:\n",
    "    print(tf_idf_count[target_chapter][target_word])\n",
    "except KeyError:\n",
    "    print(f'Слова \"{target_word}\" нет в главе {target_chapter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_BS6pPmhHdr"
   },
   "source": [
    "### Задание 4.\n",
    "\n",
    "Теперь, когда мы умеем вычислять `tf-idf` для каждого слова в главе, мы можем найти те слова, которые являются самыми «контрастными» для данной главы, то есть они могут являться в своём роде заголовком для главы.\n",
    "\n",
    "Например, для главы 3 наиболее значимыми словами будут:\n",
    "\n",
    "`\"анна\", \"павловна\", \"функе\"`\n",
    "\n",
    "**Задание:**\n",
    "\n",
    "Напишите программу, которая позволяет вывести три слова, имеющие самое высокое значение `tf-idf` в заданной главе `target_chapter` в порядке убывания `tf-idf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2k6BzGFJiIAH"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['павловна', 'анна', 'функе']\n"
     ]
    }
   ],
   "source": [
    "# Это сложный способ\n",
    "cont_words_number = 3                                # сколько слов ищем\n",
    "target_chapter = 3\n",
    "tf_idf_chapter = tf_idf_count[target_chapter].copy() # Т.к. мы будем удалять слова из словаря, то чтобы исходный оставался неизменным сделаем копию.\n",
    "c_words_list = []                                    # найденные слова будем добавлять в список\n",
    "\n",
    "for i in range(cont_words_number):                   # в каждой итерации цикла ищем самое котрастное слово и удаляем его из словаря\n",
    "    max_tf_idf = float('-inf')                       # будем добавлять сюда максимальное значение котрастности \n",
    "    contrast_word = []                               # сюда добавим самое контрастное слово. Можно было сделать строкой, но строки неизменяемые - будет утечка памяти при перезаписи.\n",
    "    for word, tf_idf in tf_idf_chapter.items():      # итерируем весь словарь главы по словам и значениям tf-idf\n",
    "        if tf_idf > max_tf_idf:                      # проверка на \"максимальность\":\n",
    "            max_tf_idf = tf_idf                      # если проверка прошла, то перезаписываем значение максимума...\n",
    "            contrast_word = [word]                   # ...и заменяем промежуточное самое котрастное слово\n",
    "    tf_idf_chapter.pop(contrast_word[0])             # после того как прошли весь словарь. удаляем это слово из словаря методом dict.pop()\n",
    "    c_words_list.append(contrast_word[0])            # записываем найденое слово с список самых котрастных слов \n",
    "\n",
    "print(c_words_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "павловна\n",
      "анна\n",
      "функе\n"
     ]
    }
   ],
   "source": [
    "# Этот гораздо проще, но в нем используются еще неизученные приемы\n",
    "cont_words_number = 3\n",
    "target_chapter = 3\n",
    "tf_idf_chapter = tf_idf_count[target_chapter].copy()\n",
    "sorted_dict = sorted(tf_idf_chapter.items(), key=lambda x:x[1], reverse=True)\n",
    "for i, item in enumerate(sorted_dict):\n",
    "    print(item[0])\n",
    "    if i == cont_words_number - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPH9eOae5CiASCO7GOW7iZr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
